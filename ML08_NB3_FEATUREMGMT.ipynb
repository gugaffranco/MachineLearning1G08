{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6459ca5",
   "metadata": {},
   "source": [
    "<h1 style = \"color : #0EE071; text-align : center;\"><em>Nata Project</em> - Feature Management Notebook</h1>\n",
    "<p style = \"font-size : 16px; text-align: center;\">This notebook has the funcion of preparing the features for the learning model.</p>\n",
    "<br>\n",
    "<p style = \"font-size : 12px; text-align: center;\"><b>NOVA IMS</b></p>\n",
    "<p style = \"font-size : 10px; text-align: center;\">Machine Learning I</p>\n",
    "<p style = \"font-size : 10px; text-align: center;\">Diogo Gonçalves, João Marques, Juan Mendes, Gustavo Franco & Lucas Casimiro</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5ca14",
   "metadata": {},
   "source": [
    "\n",
    "## <a class=\"anchor\" id=\"0th-bullet\">Table of Contents</a>\n",
    "\n",
    "\n",
    "* [<b>1. Preparation</b>](#1st-bullet)<br>\n",
    "    * [1.1 Import the needed libraries and datasets](#2nd-bullet)<br>\n",
    "    * [1.2 Scaling](#4.5th-bullet)<br>\n",
    "    \n",
    "    \n",
    "* [<b>2. Feature Selection</b>](#5th-bullet)<br>\n",
    "    * [2.1 Handling Multicolinearity](#6th-bullet)<br>\n",
    "    * [2.2 Filter methods](#6th-bullet)<br>\n",
    "        * 2.2.1 Constant features<br>\n",
    "        * 2.2.2 Spearman Correlation<br>\n",
    "        * 2.2.3 Chi-Square<br>\n",
    "    * [2.3 Wrapper Methods](#10th-bullet)<br>\n",
    "        * 2.2.1 RFE<br>\n",
    "    * [2.4 Embedded Methods](#12th-bullet)<br>\n",
    "        * 2.3.1 Lasso<br>\n",
    "    * [2.5 Final Insights](#15th-bullet)<br>\n",
    "\n",
    "\n",
    "* [<b>3. Comparing models</b>](#16th-bullet)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fd4b0",
   "metadata": {},
   "source": [
    "<hr style = \"border: 3px solid #0EE071;\">\n",
    "<h2  style = \"color : #0EE071;\"> 1. Preparation</h2>\n",
    "<h3 style=\"color: #0EE071;\">1.1 Import the needed libraries and datasets</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('Nata_files/data_clean/X_train_clean.pkl')\n",
    "X_test = pd.read_pickle('Nata_files/data_clean/X_test_clean.pkl')\n",
    "y_train = pd.read_pickle('Nata_files/data_clean/y_train_clean.pkl')\n",
    "y_test = pd.read_pickle('Nata_files/data_clean/y_test_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfade0c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #0EE071;\">1.2 Feature Scaling</h3>\n",
    "<p style = \"font-size : 15px;\">To optimize our model, we must address the different scales and distributions of our data. In this section, we'll apply Standard Scaling to center all numerical variables at a mean of 0 and variance of 1. This prevents features with larger magnitudes from dominating the model's learning process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numerical columns for scaling\n",
    "features_to_scale = X_train.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Defining the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting only the training data and transforming both \n",
    "X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63038d8",
   "metadata": {},
   "source": [
    "<hr style = \"border: 3px solid #0EE071;\">\n",
    "<h2  style = \"color : #0EE071;\"> 2. Feature Selection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a930518",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #0EE071;\">2.1 Handling Multicolinearity</h3>\n",
    "\n",
    "\n",
    "As seen in the correlation heatmap in NB1, we see 'oven_temperature' and 'final_temperature' have an extremely high correlation, which means having both is redundant, so 'final_temperature' will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('final_temperature', axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
